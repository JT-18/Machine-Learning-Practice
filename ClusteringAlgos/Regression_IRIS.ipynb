{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Regression_IRIS.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhPT29agsvZ9"
      },
      "source": [
        "### **Importing required packages.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBaTPQ81rTKg"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "path = 'iris.data'"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CORWPqDuOja"
      },
      "source": [
        "### **Reading IRIS Dataset.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LZNsLcjuf6q"
      },
      "source": [
        "def read_IRIS_Data(path):\n",
        "  df = pd.read_csv(path,names = ['SepalLength(cm)','SepalWidth(cm)','PetalLength(cm)','PetalWidth(cm)','Class'])\n",
        "  class_map = {'Iris-setosa' : 0,'Iris-versicolor' : 1,'Iris-virginica' : 2}\n",
        "  df.replace({'Class': class_map},inplace = True)\n",
        "  df_test = df.sample(n = 15)\n",
        "  unique = (df.index).difference(df_test.index) # Set difference.\n",
        "  df_train = df.filter(items = unique,axis = 'index')\n",
        "  return df_train,df_test\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBpJlK0ynVKF"
      },
      "source": [
        "### **Sigmoid**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQVSmHYSnZ7m"
      },
      "source": [
        "def sigmoid(z):\n",
        " return 1/(1+np.exp(-z))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0dJL0y__kRk"
      },
      "source": [
        "### **Regression Classifier for IRIS Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UQYuxJW_rnq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eaab2d99-b4ac-4fab-b478-166c5ef99c36"
      },
      "source": [
        "\n",
        "df_train,df_test = read_IRIS_Data(path)\n",
        "# Generating the Input feature vectors for training as well as testing.\n",
        "X_train = np.array(df_train.drop(['Class'],1)).T\n",
        "Y_train = np.array(df_train['Class'])\n",
        "m = Y_train.shape[0]\n",
        "Y_train_0 = np.where(Y_train > 0,0.0,1.0).reshape(1,m)\n",
        "Y_train_1 = np.where(Y_train == 1,1.0,0.0).reshape(1,m)\n",
        "Y_train_2 = np.where(Y_train < 2,0.0,1.0).reshape(1,m)\n",
        "X_test = np.array(df_test.drop(['Class'],1)).T\n",
        "Y_test = np.array(df_test['Class']).reshape(1,X_test.shape[1]).squeeze()\n",
        "\n",
        "\n",
        "print(\"X_train:\" + (str)(X_test.shape))\n",
        "print(\"Y_train:\" + (str)(Y_test.shape))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train:(4, 15)\n",
            "Y_train:(15,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RVFP1JcmA66"
      },
      "source": [
        "### **Generating Logistic Regression Model for each class**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPCbtNKJmBXB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ca7b8ee-434e-4d2c-8e97-0c9afe693253"
      },
      "source": [
        "learning_rate = 0.05\n",
        "\n",
        "\n",
        "#Training Regression unit for Class 0 \n",
        "#Initializing weight matrix and hyper parameters\n",
        "print(\"Training Regression unit for class 0\")\n",
        "W10 = np.random.rand(4,1) * 0.001\n",
        "b10 = np.zeros([1,1])\n",
        "for i in range(500):\n",
        "  Z1 = W10.T @ X_train + b10\n",
        "  A1 = sigmoid(Z1)\n",
        "  Y_predict = np.where(A1 > 0.5,1,0)\n",
        "  acc_train = 1- np.sum(np.abs(Y_train_0 - Y_predict))/m\n",
        "  #Calculate the cost\n",
        "  cost_per_itr = -(Y_train_0 @ (np.log(A1)).T + (1-Y_train_0) @ (np.log(1-A1)).T)/m\n",
        "  if i%50 == 0:\n",
        "    print(\"Iteration No :{:4d}     Cost:{:.4f}     Training Acc :{:.4f}\".format(i,cost_per_itr[0][0],acc_train))\n",
        "  #Calculate change in weights\n",
        "  dw = (np.dot(X_train,(A1-Y_train_0).T))/m\n",
        "  db = (np.sum(A1-Y_train_0,axis = 1,keepdims = True))/m\n",
        "  #print(f\"db after {i} th iteration : {db.shape}\")\n",
        "\n",
        "  #Update weights\n",
        "  W10 = W10 - learning_rate*dw\n",
        "  b10 = b10 - learning_rate*db\n",
        "\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Regression unit for class 0\n",
            "Iteration No :   0     Cost:0.6955     Training Acc :0.3407\n",
            "Iteration No :  50     Cost:0.1862     Training Acc :1.0000\n",
            "Iteration No : 100     Cost:0.1070     Training Acc :1.0000\n",
            "Iteration No : 150     Cost:0.0754     Training Acc :1.0000\n",
            "Iteration No : 200     Cost:0.0585     Training Acc :1.0000\n",
            "Iteration No : 250     Cost:0.0479     Training Acc :1.0000\n",
            "Iteration No : 300     Cost:0.0407     Training Acc :1.0000\n",
            "Iteration No : 350     Cost:0.0354     Training Acc :1.0000\n",
            "Iteration No : 400     Cost:0.0314     Training Acc :1.0000\n",
            "Iteration No : 450     Cost:0.0282     Training Acc :1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9-81Vx2r944",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad7c13aa-9a27-4a42-9f6a-3caf8e32ab5a"
      },
      "source": [
        "#Regression Model for class 1 (Linearly Non Seperable)\n",
        "\n",
        "W11 = np.random.rand(4,1) * 0.001\n",
        "b11 = np.zeros([1,1])\n",
        "print(\"\\nTraining Regression Unit for class 1\")\n",
        "for i in range(500):\n",
        "  Z1 = W11.T @ X_train + b11\n",
        "  A1 = sigmoid(Z1)\n",
        "  Y_predict = np.where(A1 > 0.5,1,0)\n",
        "  acc_train = 1- np.sum(np.abs(Y_train_1 - Y_predict))/m\n",
        "  #Calculate the cost\n",
        "  cost_per_itr = -(Y_train_1 @ (np.log(A1)).T + (1-Y_train_1) @ (np.log(1-A1)).T)/m\n",
        "  if i%50 == 0:\n",
        "    print(\"Iteration No :{:4d}     Cost:{:.4f}     Training Acc :{:.4f}\".format(i,cost_per_itr[0][0],acc_train))\n",
        "  #Calculate change in weights\n",
        "  dw = (np.dot(X_train,(A1-Y_train_1).T))/m\n",
        "  db = (np.sum(A1-Y_train_1,axis = 1,keepdims = True))/m\n",
        "  #print(f\"db after {i} th iteration : {db.shape}\")\n",
        "\n",
        "  #Update weights\n",
        "  W11 = W11 - learning_rate*dw\n",
        "  b11 = b11 - learning_rate*db\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Training Regression Unit for class 1\n",
            "Iteration No :   0     Cost:0.6945     Training Acc :0.3407\n",
            "Iteration No :  50     Cost:0.5932     Training Acc :0.6593\n",
            "Iteration No : 100     Cost:0.5811     Training Acc :0.6444\n",
            "Iteration No : 150     Cost:0.5748     Training Acc :0.6148\n",
            "Iteration No : 200     Cost:0.5696     Training Acc :0.6148\n",
            "Iteration No : 250     Cost:0.5651     Training Acc :0.6222\n",
            "Iteration No : 300     Cost:0.5609     Training Acc :0.6296\n",
            "Iteration No : 350     Cost:0.5571     Training Acc :0.6296\n",
            "Iteration No : 400     Cost:0.5536     Training Acc :0.6296\n",
            "Iteration No : 450     Cost:0.5503     Training Acc :0.6296\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTn8NEOcsj2m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "643fc933-d834-4176-a5bf-f2eb6eacf2df"
      },
      "source": [
        "W12 = np.random.rand(4,1) * 0.001\n",
        "b12 = np.zeros([1,1])\n",
        "print(\"\\nTraining Regression Unit for class 2\")\n",
        "for i in range(500):\n",
        "  Z1 = W12.T @ X_train + b12\n",
        "  A1 = sigmoid(Z1)\n",
        "  Y_predict = np.where(A1 > 0.5,1,0)\n",
        "  acc_train = 1- np.sum(np.abs(Y_train_2 - Y_predict))/m\n",
        "  #Calculate the cost\n",
        "  cost_per_itr = -(Y_train_2 @ (np.log(A1)).T + (1-Y_train_2) @ (np.log(1-A1)).T)/m\n",
        "  if i%100 == 0:\n",
        "    print(\"Iteration No :{:4d}     Cost:{:.4f}     Training Acc :{:.4f}\".format(i,cost_per_itr[0][0],acc_train))\n",
        "  #Calculate change in weights\n",
        "  dw = (np.dot(X_train,(A1-Y_train_2).T))/m\n",
        "  db = (np.sum(A1-Y_train_2,axis = 1,keepdims = True))/m\n",
        "  #print(f\"db after {i} th iteration : {db.shape}\")\n",
        "\n",
        "  #Update weights\n",
        "  W12 = W12 - learning_rate*dw\n",
        "  b12 = b12 - learning_rate*db\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Training Regression Unit for class 2\n",
            "Iteration No :   0     Cost:0.6936     Training Acc :0.3185\n",
            "Iteration No : 100     Cost:0.3431     Training Acc :0.9778\n",
            "Iteration No : 200     Cost:0.2861     Training Acc :0.9704\n",
            "Iteration No : 300     Cost:0.2543     Training Acc :0.9778\n",
            "Iteration No : 400     Cost:0.2320     Training Acc :0.9778\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqdMPQm1tVMG"
      },
      "source": [
        "### **Combining all the regression units for testing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Juz6gc2tm8T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6b51891-5d05-4fec-a476-9c912c314339"
      },
      "source": [
        "Y_predict_0 = sigmoid(W10.T @ X_test + b10)\n",
        "Y_predict_0 = np.where(Y_predict_0 > 0.5,0,10).squeeze()\n",
        "Y_predict_1 = sigmoid(W11.T @ X_test + b11)\n",
        "Y_predict_1 = np.where(Y_predict_1 > 0.5,1,10).squeeze()\n",
        "Y_predict_2 = sigmoid(W12.T @ X_test + b12)\n",
        "Y_predict_2 = np.where(Y_predict_2 > 0.5,2,10).squeeze()\n",
        "\n",
        "\n",
        "Y_final = []\n",
        "cnt = 0\n",
        "for i in range(Y_test.shape[0]):\n",
        "  if Y_test[i] == Y_predict_0[i]:\n",
        "    cnt += 1\n",
        "    Y_final.append(Y_predict_0[i])\n",
        "  elif Y_test[i] == Y_predict_1[i]:\n",
        "    cnt += 1\n",
        "    Y_final.append(Y_predict_1[i])\n",
        "  elif Y_test[i] == Y_predict_2[i]:\n",
        "    cnt += 1\n",
        "    Y_final.append(Y_predict_2[i])\n",
        "  else:\n",
        "    Y_final.append(2)\n",
        "\n",
        "print(\"Accuracy : \" + (str)(cnt/Y_test.shape[0]))\n",
        "c_mat = confusion_matrix(Y_test.tolist(),Y_final)\n",
        "df = pd.DataFrame(c_mat) \n",
        "print(\"Confusion Matrix\")\n",
        "print(df)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.8\n",
            "Confusion Matrix\n",
            "   0  1  2\n",
            "0  4  0  0\n",
            "1  0  1  3\n",
            "2  0  0  7\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}